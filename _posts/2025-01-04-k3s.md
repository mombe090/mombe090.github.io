---
title: 'K3s la distribution kubernetes l√©g√®re, performante et tr√®s √©fficace √† petite comme √† grande echelle'
categories: [kubernetes, k3s, cluster, production]
tags: [kubernetes]
author: "@mombe090"
---

# üìö Cr√©er un cluster Kubernetes pr√™t pour la production avec la distribution open source k3s
![](../assets/header/k3s-header.png)

#### Si vous avez besoin d'un cluster kubernetes pour tester des choses en local, opter pour des solutions comme [kind](https://kind.sigs.k8s.io/), un article est disponible ici : [D√©marrer un cluster kubernetes en quelques secondes avec kind](https://mombe090.github.io/posts/kind/).

## Contexte :
Il existe plusieurs distrubitions kubernetes production ready et se categorise en deux types :
- ### G√©rer par une entreprise externe :
  - Si vous √™tes une grosse bo√Æte et que le budget, ce n'est pas un probl√®me, cela peut √™tre une bonne option.
  - Plusieurs clouds providers offrent des services de gestion de kubernetes, comme :
    - [EKS](https://aws.amazon.com/eks/) : Amazon Elastic Kubernetes Service
    - [AKS](https://azure.microsoft.com/en-us/services/kubernetes-service/) : Azure Kubernetes Service
    - [GKE](https://cloud.google.com/kubernetes-engine) : Google Kubernetes Engine
    - [digitalocean](https://www.digitalocean.com/products/kubernetes/) : DigitalOcean Kubernetes
    - [linode](https://www.linode.com/products/kubernetes/) : Linode Kubernetes
    - [scaleway](https://www.scaleway.com/en/kubernetes-kapsule/) : Scaleway Kubernetes
    - etc ...
  - Quelque-uns proposent aussi des options hybrid (cloud + onprem) ou onprem uniquement comme :
    - [Rancher Kubernetes Engine](https://rancher.com/) : 
    - [RedHat OpenShift](https://www.openshift.com/)  
    - [Google anthos](https://cloud.google.com/anthos) 
    - [VMware Tanzu](https://tanzu.vmware.com/)
    - [Microsoft Azure Arc](https://azure.microsoft.com/en-us/services/azure-arc/) 
    - etc ...
    
- #### Avantages :
    - Ces services sont g√©r√©s par des experts pay√©s pour le maintien et la s√©curit√© votre cluster.
    - Facilite la scalabilit√© jusqu'√† tenir les traffics les plus √©lev√©s et les plus critiques aux mondes.
    - Haute disponibilit√©
    - Backup et restauration
    - Gestion des certificats SSL
    - Gestion de la persistance des donn√©es avec solution tr√®s √©fficace et perfomante.
    - ... Finalement, vous ne vous concentrez que sur l'essentiel, vos workloads et votre business.
  
- #### Inconv√©nients :
    - Ces avantages ci-haut ont un co√ªt associ√©. (√ßa peut aller jusqu'√† plusieurs milliers de dollars par mois)
      - Par experience, la facture peut rapidement devenir le plus grand sujet de discussion entre CFO et CTO.
      - ***il existe tout de m√™me des solutions pour mitiger le co√ªt comme [karpenter](https://karpenter.sh/) et [kube-green](https://kube-green.dev/) qui permet de scaler les n≈ìuds en fonction de la charge, par example (moin d'EC2 durant la nuit si le traffic est bas et r√©√©quilibre au besoin durant la journ√©e).***
      - Vous avez un contr√¥le limit√© sur les n≈ìuds de votre cluster.

- ### G√©rer par vous-m√™me :
  - Si les comp√©tences pour g√©rer un cluster kubernetes sont pr√©sentes dans votre √©quipe, vous pouvez opter pour une distribution kubernetes open source et la faire fonctionner par vous-meme et aussi souscrire √† du support aux besoins, pour les journ√©es o√π les competences en interne sont limit√©es pour de plus grands probl√®mes que vous allez surement rencontrer.
  - Certes existe plusieurs challenges (stockag√©, s√©curit√©, r√©seaux, kubernetes lui-m√™me est complexe √† troubleshooter) qui sont absorb√©s dans le cas de la gestion par une entreprise externe.
  - Cela peut √™tre une bonne option pour les petites et moyennes entreprises qui veulent √©conomiser de l'argent.
  - En plus, vous avez le contr√¥le total sur votre cluster et vous pouvez les adapter √† vos besoins.
  - Il existe plusieurs distributions kubernetes open source pr√™tent pour la production, voici queques exemples les plus connues et certifi√©es par la [CNCF](https://www.cncf.io) :
    - [k3s](https://k3s.io/) : D√©veloper par [Rancher](https://rancher.com/), c'est une distribution kubernetes l√©g√®re et facile √† installer, sur des machines avec peu de resources.
    - [k0s](https://k0sproject.io/) : D√©veloper par [Mirantis](https://www.mirantis.com), tr√®s similaire √† k3s.
    - [microk8s](https://microk8s.io/) : la distribution kubernetes de [Canonical](https://canonical.com).
    - [kubeadm](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/) : l'outil de bootstrap de kubernetes qui a √©t√© pendant longtemps la seule option production ready pour installer kubernetes (un peu plus complex √† g√©rer par rapport aux autres sur la liste).
    - [kubespray](https://kubespray.io/) : sous la gouvernance du **Kubernetes Interest Groups (SIG)**, elle permet de d√©ployer un cluster kubernetes sur plusieurs machines onprem comme sur du cloud.

  #### Avantages :
  - B√©n√©fices des avantages de kubernetes sans exploser votre budget.
  - Un contr√¥le total sur votre control-plane ainsi que les n≈ìuds.
  - Faire monter √©quipe en competences et en connaissances sur kubernetes.
  - Aujourd'hui, il est possible d'utiliser plusieurs outils open source pour mitiger les downtime et les autres probl√®mes.
  
  #### Inconv√©nients :
  - Vous devez tout faire par vos √©quipes
  - Donc des comp√©tences techniques sur l'√©cosyst√®me de kubernetes sont n√©cessaires.
  - Vous occupez de la maintenance, mise √† jour des packets, application  
  - G√©rer des firewalls, routers, etc ...
  - Faire des patch de s√©curit√©.
  - Trouvez un moin √©fficace de g√©rer la scalabilit√© Vertical et Horizontal
  - Faire de la redondance de site
   ... 

## Objectif :
Sur cet article, nous allons voir comment installer un cluster kubernetes pr√™t pour la production avec [k3s](https://k3s.io/) 
et d√©ployer le serveur web [nginx](https://www.nginx.com/) comme exemple de workload.

### Cr√©ation des n≈ìuds (VMs) qui vont former notre cluster kubernetes :

  - Pour faire simple, nous allons cr√©er 3 n≈ìuds (VMs) :
    - 1 n≈ìud qui va servir de control-plane k8s appel√© **server** dans le contexte de k3s.
    - 2 n≈ìuds pour les workers ou **agents**.
    - Il existe plusieurs solutions et outils pour cr√©er des machines virtuelles, comme : <br>
    Voici quelques-un les plus populaires sur des workstation :
      - [VirtualBox](https://www.virtualbox.org/)
      - [VMware Workstation ou Fusion](https://www.vmware.com/products/desktop-hypervisor/workstation-and-fusion)
      - [Microsoft Hyper-V](https://docs.microsoft.com/en-us/virtualization/hyper-v-on-windows/)
      - [KVM](https://www.linux-kvm.org/page/Main_Page)
      - [QEMU](https://www.qemu.org/)
  
  - il y a aussi quelques outils qui facilitent la gestion de ces VMs : <br />
  Ces outils fournissent des configurations d√©claratives ou adhoc via une CLI pour la gestion de tout le cycle de vie des VMs.
    - [Vagrant](https://www.vagrantup.com/) de [HashiCorp](https://www.hashicorp.com/) qui a √©t√© le pionnier dans ce domaine.
    - [Multipass](https://multipass.run/) de [Canonical](https://canonical.com/) qui se d√©marque par sa simplicit√©. <br />

#### Nous allons utiliser multipass pour cr√©er nos VMs :
- Multipass simplifie la gestion des machines virtuelles, tout comme Docker l'a fait pour les conteneurs.
- D√©velopper chez [Canonical](https://canonical.com), il permet de cr√©er et g√©rer des machines virtuelles.
- Il supporte la method [cloudinit](https://cloudinit.readthedocs.io/en/latest/)
  - largement utilis√© pour automatiser la configuration initiale des instances de machines virtuelles (VM) dans les environnements cloud et onprem. 
  - Il permet de personnaliser vos VMs lors de la cr√©ation avec comme option : import de cl√©s ssh, de cr√©ation d'utilisateurs, installer des packets etc...)
- Il est disponible sur Windows, macOS et Linux. voir [Installer Multipass](https://canonical.com/multipass/install) et choisissez votre OS.
- Le seul inconvenient, il n'y a qu'ubuntu comme distribution support√©e pour le moment.
- Pour cr√©er une VM avec multipass, vous pouvez utiliser l'application graphique ou la CLI :
- Avec la CLI, vous pouvez utiliser la commande `multipass launch` pour cr√©er une VM avec des options comme le nombre de CPUs, la m√©moire, le disque, le nom, le r√©seau etc ...
- Ci-desous, les commandes pour cr√©er les n≈ìuds de notre cluster :
  ```bash
  multipass launch noble --name server-01 --cpus  2  --memory 2G    --disk 5G --network en0
  multipass launch noble --name agent-01  --cpus  1  --memory 512M  --disk 5G --network en0
  multipass launch noble --name agent-02  --cpus  1  --memory 512M  --disk 5G --network en0
  ```
  - *Note* : 
    - J'utilise le minimum de ressources requises pour k3s, vous pouvez augmenter les ressources si vous avez besoin. [voir le requirement](https://docs.k3s.io/installation/requirements#hardware)
    - `noble` est l'image ubuntu 24.04 LTS, vous pouvez utiliser `multipass find` pour lister les images disponibles.
    - `--network en0` est l'interface r√©seau que j'utilise, vous pouvez utiliser `multipass networks` pour lister les interfaces disponibles.
  - Si c'est votre premi√®re installation via multipass, √ßa risque de prendre un peu de temps pour t√©l√©charger l'image ubuntu (les autres fois, il cache l'image en local).
  - Apr√®s quelque temps si tout se passe bien, vous devriez avoir cette sortie :
    - ```bash
         Launched: server-01
         Launched: worker1
         Launched: worker2
    ```
  - Vous pouvez v√©rifier que les VMs sont cr√©√©es avec la commande `multipass list` (les ip sont g√©n√©r√©es automatiquement, mais vous pouvez les mettre statiques avec `cloudinit` ou directement ajuster le fichier `/etc/netplan/50-cloud-init.yaml`) :
    
    - ```bash
         Name                    State             IPv4             Image
         server-01               Running           192.168.64.3     Ubuntu 24.04 LTS
         agent-01                Running           192.168.64.4     Ubuntu 24.04 LTS
         agent-02                Running           192.168.64.5     Ubuntu 24.04 LTS
     ```
    
#### Ex√©cuter une command sur une instance de VM avec multipass :
Multipass permet d'ex√©cuter des commandes sur une VM avec la commande `multipass exec` comme docker sur lequel il s'est fortement inspir√© :

##### Exemple :
Ces commandes sont optionnelles, mais je vous recommande de les faire pour mettre √† jour les packages d'ubuntu avant d'installer k3s :

- Server-01 :
  ```bash
  multipass exec server-01 -- sudo apt update 
  multipass exec server-01 -- sudo apt upgrade -y
  ```
- Server-02 :
  ```bash
  multipass exec agent-01 -- sudo apt update 
  multipass exec agent-01 -- sudo apt upgrade -y
  ```
- Server-03 :
  ```bash
  multipass exec agent-02 -- sudo apt update 
  multipass exec agent-02 -- sudo apt upgrade -y
  ```
  
#### Se connecter √† une VM avec multipass :
En cr√©ant une instance, multipass ajoute une cl√© ssh pour se connecter √† la VM dans le fichier `/home/ubuntu/.ssh/authorized_keys` de l'utilisateur ubuntu. <br />
La cl√© priv√© est stock√©e sur votre machine en fonction de votre OS (voir [cette discussion github √† ce sujet](https://github.com/canonical/multipass/issues/913)).

```bash
$ multipass shell server-01

Welcome to Ubuntu 24.04.1 LTS (GNU/Linux 6.8.0-49-generic aarch64)
*
*
*
ubuntu@server-01:~$ 
```
***Tout est pr√™t pour installer server k3s qui represent le control-plane de notre cluster kubernetes.***

## Installation de k3s sur le control-plane (server) :
Pour installer k3s, on peut suivre le [quickstart guide](https://rancher.com/docs/k3s/latest/en/quick-start/), il y a aussi beaucoup d'options d'installation de disponibles sur la [documentation officielle](https://rancher.com/docs/k3s/latest/en/installation) que je vous conseille de lire et trouve celles qui vous conviennent. <br />

L'une des options les plus utilis√©s pour des clusters de production est celui d'avoir un cluster de haute disponibilit√© (HA) avec au moins 3 serveurs (control-plane) et un loadbalancer en avant. <br /><br />

***Si vous √™tes un peu √† l'aise avec [ansible](https://www.ansible.com/), il y a ce [d√©p√¥t github](https://github.com/techno-tim/k3s-ansible) maintenu par [TechnoTim](https://github.com/timothystewart6) qui offre un ensemble de playbooks et roles pour cr√©er un cluster kubernetes HA avec Metallb comme loadbalancer. <br />***

- ### Connectez-vous √† la VM server-01 :
  ```bash
  multipass shell server-01
  ```
- #### Une fois connect√©, vous pouvez installer k3s avec la commande suivante :
  ```bash
  curl -sfL https://get.k3s.io | sh -
  
  [INFO]  Finding release for channel stable
  [INFO]  Using v1.31.4+k3s1 as release
  [INFO]  Downloading hash https://github.com/k3s-io/k3s/releases/download/v1.31.4+k3s1/sha256sum-arm64.txt
  [INFO]  Downloading binary https://github.com/k3s-io/k3s/releases/download/v1.31.4+k3s1/k3s-arm64
  [INFO]  Verifying binary download
  [INFO]  Installing k3s to /usr/local/bin/k3s
  [INFO]  Skipping installation of SELinux RPM
  [INFO]  Creating /usr/local/bin/kubectl symlink to k3s
  [INFO]  Creating /usr/local/bin/crictl symlink to k3s
  [INFO]  Creating /usr/local/bin/ctr symlink to k3s
  [INFO]  Creating killall script /usr/local/bin/k3s-killall.sh
  [INFO]  Creating uninstall script /usr/local/bin/k3s-uninstall.sh
  [INFO]  env: Creating environment file /etc/systemd/system/k3s.service.env
  [INFO]  systemd: Creating service file /etc/systemd/system/k3s.service
  [INFO]  systemd: Enabling k3s unit
  Created symlink /etc/systemd/system/multi-user.target.wants/k3s.service ‚Üí /etc/systemd/system/k3s.service.
  [INFO]  systemd: Starting k3s
  ```
  *Simple n'est pas ?* <br />
  Rancher fait cette abstraction et tout le script qui permet de lancer k3s est fait pour vous. <br />

- #### Verifier le status du service k3s avec Systemd
```bash
  sudo systemctl status k3s
  
  ‚óè k3s.service - Lightweight Kubernetes
  Loaded: loaded (/etc/systemd/system/k3s.service; enabled; preset: enabled)
  Active: active (running) since Sat 2025-01-04 17:27:59 EST; 26s ago
  Docs: https://k3s.io
  Process: 13514 ExecStartPre=/bin/sh -xc ! /usr/bin/systemctl is-enabled --quiet nm-cloud-setup.service 2>/dev/null (code=exited, status=0/SUCCESS)
  Process: 13516 ExecStartPre=/sbin/modprobe br_netfilter (code=exited, status=0/SUCCESS)
  Process: 13520 ExecStartPre=/sbin/modprobe overlay (code=exited, status=0/SUCCESS)
  Main PID: 13521 (k3s-server)
  Tasks: 96
  Memory: 1.1G (peak: 1.1G)
  CPU: 9.538s
```

#### V√©rifier que le cluster est bien install√© :
```bash
sudo k3s kubectl get nodes

NAME        STATUS   ROLES                  AGE     VERSION
server-01   Ready    control-plane,master   10m   v1.31.4+k3s1
```
Par d√©fault k3s g√©n√®re le fichier de configuration de kubernetes sur `/etc/rancher/k3s/k3s.yaml` avec toutes les informations (ip, user, certificates ...) r√©quises pour se connecter au cluster. <br />
Pour utiliser kubectl sans `sudo`, vous pouvez copier ce fichier dans votre r√©pertoire `~/.kube/config` :

```bash
mkdir ~/.kube
sudo cp /etc/rancher/k3s/k3s.yaml ~/.kube/config
sudo chmod 755 ~/.kube/config
```
Ajoutez la ligne suivante √† votre fichier `~/.bashrc`  :
```bash
echo 'export KUBECONFIG=~/.kube/config' >> ~/.bashrc
source ~/.bashrc
```
Si vous voulez acc√©der au cluster avec kubectl ou ([headlamp](https://mombe090.github.io/posts/headlamp/) [un article est disponible sur le blog](https://mombe090.github.io/posts/headlamp/)) √† partir du votre machine h√¥te, vous pouvez copier le dossier `~/.kube` dans le dossier de l'utilisateur :

```bash
scp -rv ubuntun@ip-server-01:~/.kube .
```

Maintenant vous pouvez utiliser `kubectl` sans `sudo` :
```bash
k3s kubectl get pods --namespace kube-system

NAME                                      READY   STATUS      RESTARTS   AGE
coredns-ccb96694c-8zwdm                   1/1     Running     0          4h26m
helm-install-traefik-crd-rl97x            0/1     Completed   0          4h26m
helm-install-traefik-tvm47                0/1     Completed   1          4h26m
local-path-provisioner-5cf85fd84d-cxz5b   1/1     Running     0          4h26m
metrics-server-5985cbc9d7-9hsb2           1/1     Running     0          4h26m
svclb-traefik-260ec65e-dqnhz              2/2     Running     0          4h26m
traefik-57b79cf995-v76fj                  1/1     Running     0          4h26m
```
On voit qu'il y a quelques services d√©j√† install√©s par d√©fault avec k3s, comme traefik proxy, servicelb. <br />
`Un ingress controller et un loadbalancer sont install√©s pour votre cluster kubernetes avec trafik proxy`. <br />
Par contre pour faire simple, nous allons utiliser le service de type `NodePort` pour acc√©der √† notre application d'exemple. <br />
Un article d√©di√© aux ingress controllers, kubernetes gateway api et loadbalancer sera r√©diger bient√¥t.


#### R√©cup√©rer le token pour joindre les agents au cluster (workers/n≈ìuds) :
Sur le `server-01`, vous pouvez r√©cup√©rer le token suivant :
```bash
sudo cat /var/lib/rancher/k3s/server/node-token
```
## Installation et join des agents (workers/n≈ìuds) :
- Connectez-vous aux VMs `agent-01` et `agent-02` :
  - Exemple : `agent-01`
    ```bash
    multipass shell agent-01
    ```
- Une fois connect√©, vous pouvez installer k3s avec la commande suivante :
- Remplacer `K3S_URL` et `K3S_TOKEN` respectivement par l'IP de `server-01` et la sortie de la commande `sudo cat /var/lib/rancher/k3s/server/node-token` ci-haut : 
  ```bash
  curl -sfL https://get.k3s.io | K3S_URL=https://192.168.64.3:6443 K3S_TOKEN=remplacer-le-votre-ici sh -
  
  [INFO]  Finding release for channel stable
  [INFO]  Using v1.31.4+k3s1 as release
  [INFO]  Downloading hash https://github.com/k3s-io/k3s/releases/download/v1.31.4+k3s1/sha256sum-arm64.txt
  [INFO]  Downloading binary https://github.com/k3s-io/k3s/releases/download/v1.31.4+k3s1/k3s-arm64
  [INFO]  Verifying binary download
  [INFO]  Installing k3s to /usr/local/bin/k3s
  [INFO]  Skipping installation of SELinux RPM
  [INFO]  Creating /usr/local/bin/kubectl symlink to k3s
  [INFO]  Creating /usr/local/bin/crictl symlink to k3s
  [INFO]  Creating /usr/local/bin/ctr symlink to k3s
  [INFO]  Creating killall script /usr/local/bin/k3s-killall.sh
  [INFO]  Creating uninstall script /usr/local/bin/k3s-agent-uninstall.sh
  [INFO]  env: Creating environment file /etc/systemd/system/k3s-agent.service.env
  [INFO]  systemd: Creating service file /etc/systemd/system/k3s-agent.service
  [INFO]  systemd: Enabling k3s-agent unit
  Created symlink /etc/systemd/system/multi-user.target.wants/k3s-agent.service ‚Üí /etc/systemd/system/k3s-agent.service.
  [INFO]  systemd: Starting k3s-agent
  ```
  
- V√©rifier le status du service k3s avec Systemd :
  ```bash
  sudo systemctl status k3s
  ```
- Faite la m√™me chose pour `agent-02` :
  ```bash
  multipass shell agent-02
  ```
  ```bash
  curl -sfL https://get.k3s.io | K3S_URL=https://192.168.64.3:6443 K3S_TOKEN=remplacer-le-votre-ici sh -
  ```
### V√©rifier que les agents sont bien join√©s au cluster :
Reconnectez-vous √† la VM `server-01` :

```bash
kubectl get nodes

NAME        STATUS   ROLES                  AGE   VERSION
server-01   Ready    control-plane,master   3m    v1.31.4+k3s1
agent-01    Ready    <none>                 2m    v1.31.4+k3s1
agent-02    Ready    <none>                 2m    v1.21.5+k3s1
```

## Installer votre premier workload sur le cluster kubernetes :
- Vous pouvez maintenant installer une application utilisant kubectl :
  - Exemple : le serveur web`nginx`
    - Cr√©er un deployment et un service nginx :
      ```bash
      kubectl create deployment nginx --image=nginx 
      ```
      ```bash
      kubectl expose deployment nginx --port=80 --target-port=80 --type=NodePort
      ```
    - V√©rifier que le pod est bien cr√©√© :
      ```bash
      kubectl get pods
      
      NAME                     READY   STATUS    RESTARTS   AGE
      nginx-676b6c5bbc-fn4bx   1/1     Running   0          85s
      ```
      
    - V√©rifier que le service est bien cr√©√© :
      ```bash
      kubectl get svc
      
      NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
      kubernetes   ClusterIP   10.43.0.1       <none>        443/TCP        4h40m
      nginx        NodePort    10.43.111.120   <none>        80:30516/TCP   52s
      ```
      Le service √† g√©n√©r√© un port al√©atoire, dans mon cas, c'est `30516`, il sera diff√©rent chez vous.
    - Vous pouvez patcher le service avec un nombre statique qui doit √™tre entre 30000 et 32767 :
    - 
      ```bash
         kubectl patch svc nginx -p '{"spec": {"ports": [{"port": 80, "nodePort": 32500}]}}'
      
         service/nginx patched
      ```
    - Vous pouvez maintenant acc√©der √† votre application en utilisant l'IP de n'importe quel n≈ìud sur le port `32900` :
      ```bash
      curl http://192.168.64.3:32500
      
      <!DOCTYPE html>
      <html>
      <head>
        <title>Welcome to nginx!</title>
        <style>
         html { color-scheme: light dark; }
         body { width: 35em; margin: 0 auto;
         font-family: Tahoma, Verdana, Arial, sans-serif; }
        </style>
      </head>
      <body>
        <h1>Welcome to nginx!</h1>
        <p>If you see this page, the nginx web server is successfully installed and
           working. Further configuration is required.
        </p>
        <p>For online documentation and support please refer to
        <a href="http://nginx.org/">nginx.org</a>.<br/>
        Commercial support is available at
        <a href="http://nginx.com/">nginx.com</a>.</p>
      
        <p><em>Thank you for using nginx.</em></p>
      </body>
      </html>

      ```
      ou sur un navigateur Web 
      ![nginx](../assets/content/k3s-nginx.png)

## Supprimer les instances de vms :

```bash
multipass stop server-01 agent-01 agent-02
multipass delete server-01 agent-01 agent-02
multipass purge
```

###  Lire doc de k3s, il y a plusieurs options d'installation possibles et amusez-vous ‚ö°Ô∏è!

## R√©f√©rences
- [k3s](https://k3s.io/)
- [k3s documentation](https://rancher.com/docs/k3s/latest/en/)
- [multipass](https://multipass.run/)
- [cloudinit](https://cloudinit.readthedocs.io/en/latest/)


